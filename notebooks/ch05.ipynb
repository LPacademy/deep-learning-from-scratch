{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5章 誤差逆伝播法\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 計算グラフ\n",
    "\n",
    "視覚的に順伝播・逆伝播を理解する方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 連鎖律\n",
    "\n",
    "連鎖律とは以下のような合成関数の微分についての性質を示す\n",
    "\n",
    "> ある関数が合成関数で表される場合、その合成関数の微分は、合成関数を構成するそれぞれの関数の微分の積によって表すことができる。\n",
    ">\n",
    "> <div style=\"text-align: right;\"><cite>\"ゼロから作るDeep Learning\", p. 130</cite></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 逆伝播\n",
    "\n",
    "* 加算ノードの逆伝播では右側からの信号をそのまま左のノードへ出力する\n",
    "* 乗算ノードの逆伝播では右側からの信号に順伝播の際の入力信号をひっくり返した値を乗算して左のノードへ出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 単純なレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 乗算レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# ch05/layer_naive.py #\n",
    "#######################\n",
    "\n",
    "class MulLayer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        return dx, dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 220.00000000000003\n",
      "dapple: 2.2\n",
      "dapple_num: 110.00000000000001\n",
      "dtax: 200\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# ch05/buy_apple.py #\n",
    "#####################\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "print('price: ' + str(price))\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "print('dapple: ' + str(dapple))\n",
    "print('dapple_num: ' + str(dapple_num))\n",
    "print('dtax: ' + str(dtax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# ch05/layer_naive.py #\n",
    "#######################\n",
    "\n",
    "class AddLayer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715.0000000000001\n",
      "dapple_num: 110.00000000000001\n",
      "dapple: 2.2\n",
      "dorange: 3.3000000000000003\n",
      "dorange_num: 165.0\n",
      "dtax: 650\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# ch05/buy_apple_orange.py #\n",
    "############################\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print('price: ' + str(price))\n",
    "print('dapple_num: ' + str(dapple_num))\n",
    "print('dapple: ' + str(dapple))\n",
    "print('dorange: ' + str(dorange))\n",
    "print('dorange_num: ' + str(dorange_num))\n",
    "print('dtax: ' + str(dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 活性化関数レイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 ReLUレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# common/layer.py #\n",
    "###################\n",
    "\n",
    "class Relu:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoidレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# common/layer.py #\n",
    "###################\n",
    "\n",
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine / Softmaxレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 Affineレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dout(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3 Softmax-with-Lossレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# common/layer.py #\n",
    "###################\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import cross_entropy_error, softmax\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 誤差逆伝播法の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 ニューラルネットワークの学習の全体図\n",
    "1. ミニバッチの作成\n",
    "2. 勾配の算出\n",
    "3. パラメータの更新\n",
    "4. 繰り返し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# ch05/two_layer_net.py #\n",
    "#########################\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 :\n",
    "            t = np.argmax(t, axis=1)        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads\n",
    "    \n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7.3 誤差逆伝播法の勾配確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数値微分と誤差逆伝播法の特徴\n",
    "\n",
    "* 数値微分: 計算に時間がかかるが、実装が簡単\n",
    "* 誤差逆伝播法: 計算が速いが、実装が複雑でミスが起きやすい\n",
    "\n",
    "数値微分で求めた勾配と、誤差逆伝播法で求めた勾配の結果が一致することを確認する作業を**勾配確認**と言う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "W1:2.3545864239e-13\n",
      "b1:8.29204726801e-13\n",
      "W2:8.80419047911e-13\n",
      "b2:1.20348178645e-10\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# ch05/gradient_check.py #\n",
    "##########################\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7.4 誤差逆伝播法を使った学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147966666667 0.1492\n",
      "0.905016666667 0.9104\n",
      "0.9244 0.925\n",
      "0.937683333333 0.9388\n",
      "0.945833333333 0.9452\n",
      "0.952 0.9506\n",
      "0.955833333333 0.9545\n",
      "0.960816666667 0.9568\n",
      "0.964216666667 0.9592\n",
      "0.966233333333 0.9626\n",
      "0.969016666667 0.9639\n",
      "0.970933333333 0.9657\n",
      "0.97415 0.9674\n",
      "0.975483333333 0.9699\n",
      "0.977083333333 0.9701\n",
      "0.978266666667 0.9701\n",
      "0.97955 0.9716\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# ch05/train_neuralnet.py #\n",
    "###########################\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e7404c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_list = range(len(test_acc_list))\n",
    "plt.plot(epoch_list, train_acc_list, label=\"train\")\n",
    "plt.plot(epoch_list, test_acc_list, label=\"test\")\n",
    "plt.xlabel('n_epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "---\n",
    "\n",
    "* [誤差逆伝播法のノート](http://qiita.com/Ugo-Nama/items/04814a13c9ea84978a4c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
